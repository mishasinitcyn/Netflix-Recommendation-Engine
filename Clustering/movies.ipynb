{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering (Movies)\n",
    "In this notebook, we cluster movies based on their features using K-Means and DBSCAN algorithms. Each movie is represented as a one-hot encoded vector indicating the presence or absence of the 450 most popular movie features.\n",
    "\n",
    "Interestingly, we find that feature-rich movies with exceptionally popular \"superstar\" cast are detected as outliers by DBSCAN when applied directly to the movie features<br>\n",
    "- Batman\n",
    "- Batman Returns\n",
    "- Antz\n",
    "- Hook\n",
    "- The Royal Tenenbaums\n",
    "- Con Air\n",
    "- National Treasure\n",
    "- Sleepy Hollow\n",
    "\n",
    "Intuitively, this makes sense as the average movie has 3-5 popular features. Thus, a movie with 10-15 popular features will simply not have enough neighbours within a distance epsilon to be assigned to a cluster. We find that this result mostly disappears when peforming DBSCAN on PCA-reduced features as pure counts are replaced with principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Enable notebook renderer for Altair\n",
    "alt.renderers.enable('default')\n",
    "\n",
    "DATA_PATH = \"../data\"\n",
    "NETFLIX_FOLDER_PATH = os.path.join(DATA_PATH, \"netflix_prize\")\n",
    "IMDB_FOLDER_PATH = os.path.join(DATA_PATH, \"imdb\")\n",
    "MIN_OCCURRENCES = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load movie features\n",
    "MOVIE_FEATURES_PATH = os.path.join(DATA_PATH, f\"processed/movie_features_{MIN_OCCURRENCES}.pickle\")\n",
    "with open(MOVIE_FEATURES_PATH, \"rb\") as f:\n",
    "    movie_features = pickle.load(f)\n",
    "\n",
    "# Load feature mapping\n",
    "FEATURE_MAPPING_PATH = os.path.join(DATA_PATH, f\"processed/feature_mapping_{MIN_OCCURRENCES}.pickle\")\n",
    "with open(FEATURE_MAPPING_PATH, \"rb\") as f:\n",
    "    feature_mapping = pickle.load(f)\n",
    "\n",
    "feature_to_id = feature_mapping['feature_to_id']\n",
    "id_to_feature = feature_mapping['id_to_feature']\n",
    "\n",
    "# Number of features\n",
    "num_features = len(feature_to_id)\n",
    "print(f\"Number of features: {num_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Movie Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of movie IDs and feature IDs\n",
    "movie_ids = list(movie_features.keys())\n",
    "feature_ids = list(id_to_feature.keys())\n",
    "\n",
    "# Create an empty DataFrame\n",
    "movie_feature_matrix = pd.DataFrame(0, index=movie_ids, columns=feature_ids)\n",
    "\n",
    "# Fill the DataFrame\n",
    "for movie_id, features in movie_features.items():\n",
    "    movie_feature_matrix.loc[movie_id, features] = 1\n",
    "\n",
    "print(f\"Movie feature matrix shape: {movie_feature_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load Netflix to IMDb mapping\n",
    "NETFLIX_TO_IMDB_PATH = os.path.join(DATA_PATH, \"netflix_to_imdb.json\")\n",
    "with open(NETFLIX_TO_IMDB_PATH, \"r\") as f:\n",
    "    netflix_to_imdb = json.load(f)\n",
    "\n",
    "# Create a mapping from Netflix movie IDs to IMDb IDs\n",
    "netflix_ids = set(movie_ids)\n",
    "netflix_to_imdb_filtered = {nid: imdb_id for nid, imdb_id in netflix_to_imdb.items() if nid in netflix_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IMDb title.basics.tsv.gz\n",
    "TITLE_BASICS_PATH = os.path.join(IMDB_FOLDER_PATH, \"title.basics.tsv.gz\")\n",
    "\n",
    "imdb_titles = {}\n",
    "\n",
    "with gzip.open(TITLE_BASICS_PATH, 'rt', encoding='utf-8') as f:\n",
    "    # Skip header\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) != 9:\n",
    "            continue\n",
    "        tconst, titleType, primaryTitle, originalTitle, isAdult, startYear, endYear, runtimeMinutes, genres = parts\n",
    "        imdb_titles[tconst] = primaryTitle\n",
    "\n",
    "print(f\"Loaded {len(imdb_titles)} IMDb titles.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Netflix movie IDs to titles\n",
    "movie_titles = {}\n",
    "\n",
    "for netflix_id in movie_ids:\n",
    "    imdb_id = netflix_to_imdb_filtered.get(netflix_id)\n",
    "    if imdb_id and imdb_id in imdb_titles:\n",
    "        movie_titles[netflix_id] = imdb_titles[imdb_id]\n",
    "    else:\n",
    "        movie_titles[netflix_id] = f\"Unknown Title ({netflix_id})\"\n",
    "\n",
    "# Add movie titles to the DataFrame\n",
    "movie_feature_matrix['title'] = movie_feature_matrix.index.map(movie_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of feature names for each movie\n",
    "def get_feature_names(feature_ids):\n",
    "    return [id_to_feature[feat_id] for feat_id in feature_ids]\n",
    "\n",
    "movie_feature_matrix['features'] = movie_feature_matrix.index.map(\n",
    "    lambda x: ', '.join(get_feature_names(movie_features.get(x, [])))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clustering_metrics(data, k_range):\n",
    "    silhouette_scores = []\n",
    "    ch_scores = []\n",
    "\n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(data)\n",
    "        silhouette_scores.append(silhouette_score(data, labels))\n",
    "        ch_scores.append(calinski_harabasz_score(data, labels))\n",
    "    \n",
    "    return silhouette_scores, ch_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude 'title' and 'features' columns for clustering\n",
    "movie_feature_matrix_no_meta = movie_feature_matrix.drop(['title', 'features'], axis=1)\n",
    "\n",
    "k_range = range(2, 21)\n",
    "silhouette_scores, ch_scores = compute_clustering_metrics(movie_feature_matrix_no_meta, k_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Clustering Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "ax1.plot(k_range, silhouette_scores, marker='o')\n",
    "ax1.set_xlabel('Number of Clusters (k)')\n",
    "ax1.set_ylabel('Silhouette Score')\n",
    "ax1.set_title('Silhouette Score vs. Number of Clusters')\n",
    "\n",
    "ax2.plot(k_range, ch_scores, marker='s')\n",
    "ax2.set_xlabel('Number of Clusters (k)')\n",
    "ax2.set_ylabel('Calinski-Harabasz Index')\n",
    "ax2.set_title('Calinski-Harabasz Index vs. Number of Clusters')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the best k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = k_range[np.argmax(silhouette_scores)]\n",
    "print(f\"Best k according to Silhouette Score: {best_k}\")\n",
    "\n",
    "# Perform K-Means clustering with the best k\n",
    "kmeans = KMeans(n_clusters=best_k, random_state=42)\n",
    "labels = kmeans.fit_predict(movie_feature_matrix_no_meta)\n",
    "\n",
    "# Add cluster labels to the DataFrame\n",
    "movie_feature_matrix['cluster'] = labels.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Clusters in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA to reduce to 2 dimensions\n",
    "pca = PCA(n_components=2)\n",
    "movie_features_2d = pca.fit_transform(movie_feature_matrix_no_meta)\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "plot_df = pd.DataFrame(movie_features_2d, columns=['PC1', 'PC2'])\n",
    "plot_df['title'] = movie_feature_matrix['title'].values\n",
    "plot_df['features'] = movie_feature_matrix['features'].values\n",
    "plot_df['cluster'] = movie_feature_matrix['cluster'].values\n",
    "\n",
    "# Create an interactive scatter plot using Altair\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "scatter = alt.Chart(plot_df).mark_circle(size=60).encode(\n",
    "    x=alt.X('PC1', scale=alt.Scale(zero=False)),\n",
    "    y=alt.Y('PC2', scale=alt.Scale(zero=False)),\n",
    "    color='cluster:N',\n",
    "    tooltip=['title', 'features']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600,\n",
    "    title='K-Means Clustering of Movies Visualized in 2D'\n",
    ").interactive()\n",
    "\n",
    "scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to 50 principal components\n",
    "pca_full = PCA(n_components=50)\n",
    "movie_features_pca = pca_full.fit_transform(movie_feature_matrix_no_meta)\n",
    "\n",
    "print(f\"Explained variance ratio of 50 components: {np.sum(pca_full.explained_variance_ratio_):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(2, 21)\n",
    "silhouette_scores_pca, ch_scores_pca = compute_clustering_metrics(movie_features_pca, k_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "ax1.plot(k_range, silhouette_scores_pca, marker='o')\n",
    "ax1.set_xlabel('Number of Clusters (k)')\n",
    "ax1.set_ylabel('Silhouette Score')\n",
    "ax1.set_title('Silhouette Score vs. Number of Clusters (PCA Reduced Data)')\n",
    "\n",
    "ax2.plot(k_range, ch_scores_pca, marker='s')\n",
    "ax2.set_xlabel('Number of Clusters (k)')\n",
    "ax2.set_ylabel('Calinski-Harabasz Index')\n",
    "ax2.set_title('Calinski-Harabasz Index vs. Number of Clusters (PCA Reduced Data)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k_pca = k_range[np.argmax(silhouette_scores_pca)]\n",
    "print(f\"Best k according to Silhouette Score (PCA Data): {best_k_pca}\")\n",
    "\n",
    "# Perform K-Means clustering with the best k\n",
    "kmeans_pca = KMeans(n_clusters=best_k_pca, random_state=42)\n",
    "labels_pca = kmeans_pca.fit_predict(movie_features_pca)\n",
    "\n",
    "# Add cluster labels to the DataFrame\n",
    "movie_feature_matrix['cluster_pca'] = labels_pca.astype(str)\n",
    "\n",
    "# Further reduce to 2 principal components for visualization\n",
    "pca_2d = PCA(n_components=2)\n",
    "movie_features_2d_pca = pca_2d.fit_transform(movie_features_pca)\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "plot_df_pca = pd.DataFrame(movie_features_2d_pca, columns=['PC1', 'PC2'])\n",
    "plot_df_pca['title'] = movie_feature_matrix['title'].values\n",
    "plot_df_pca['features'] = movie_feature_matrix['features'].values\n",
    "plot_df_pca['cluster'] = movie_feature_matrix['cluster_pca'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive scatter plot using Altair\n",
    "scatter_pca = alt.Chart(plot_df_pca).mark_circle(size=60).encode(\n",
    "    x=alt.X('PC1', scale=alt.Scale(zero=False)),\n",
    "    y=alt.Y('PC2', scale=alt.Scale(zero=False)),\n",
    "    color='cluster:N',\n",
    "    tooltip=['title', 'features']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600,\n",
    "    title='K-Means Clustering of Movies (PCA Reduced Data) Visualized in 2D'\n",
    ").interactive()\n",
    "\n",
    "scatter_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_k_distance(data, k):\n",
    "    nbrs = NearestNeighbors(n_neighbors=k).fit(data)\n",
    "    distances, indices = nbrs.kneighbors(data)\n",
    "    distances = np.sort(distances[:, k-1], axis=0)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(distances)\n",
    "    plt.ylabel(f'{k}th Nearest Neighbor Distance')\n",
    "    plt.xlabel('Data Points sorted by distance')\n",
    "    plt.title(f'K-distance Graph for k={k}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_k_distance(movie_feature_matrix_no_meta, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 2.5 \n",
    "dbscan = DBSCAN(eps=epsilon, min_samples=5)\n",
    "dbscan_labels = dbscan.fit_predict(movie_feature_matrix_no_meta)\n",
    "\n",
    "# Add labels to the DataFrame\n",
    "movie_feature_matrix['dbscan_cluster'] = dbscan_labels.astype(str)\n",
    "plot_df['dbscan_cluster'] = dbscan_labels.astype(str)\n",
    "\n",
    "# Create an interactive scatter plot using Altair\n",
    "scatter_dbscan = alt.Chart(plot_df).mark_circle(size=60).encode(\n",
    "    x=alt.X('PC1', scale=alt.Scale(zero=False)),\n",
    "    y=alt.Y('PC2', scale=alt.Scale(zero=False)),\n",
    "    color='dbscan_cluster:N',\n",
    "    tooltip=['title', 'features']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600,\n",
    "    title='DBSCAN Clustering of Movies Visualized in 2D'\n",
    ").interactive()\n",
    "\n",
    "scatter_dbscan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_k_distance(movie_features_pca, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_pca = 1.5  # Adjust based on the k-distance graph for PCA data\n",
    "dbscan_pca = DBSCAN(eps=epsilon_pca, min_samples=5)\n",
    "dbscan_labels_pca = dbscan_pca.fit_predict(movie_features_pca)\n",
    "\n",
    "# Add labels to the DataFrame\n",
    "movie_feature_matrix['dbscan_cluster_pca'] = dbscan_labels_pca.astype(str)\n",
    "plot_df_pca['dbscan_cluster'] = dbscan_labels_pca.astype(str)\n",
    "\n",
    "# Create an interactive scatter plot using Altair\n",
    "scatter_dbscan_pca = alt.Chart(plot_df_pca).mark_circle(size=60).encode(\n",
    "    x=alt.X('PC1', scale=alt.Scale(zero=False)),\n",
    "    y=alt.Y('PC2', scale=alt.Scale(zero=False)),\n",
    "    color='dbscan_cluster:N',\n",
    "    tooltip=['title', 'features']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=600,\n",
    "    title='DBSCAN Clustering of Movies (PCA Reduced Data) Visualized in 2D'\n",
    ").interactive()\n",
    "\n",
    "scatter_dbscan_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
