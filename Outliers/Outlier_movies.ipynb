{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Detection (Movies)\n",
    "In this notebook, we compute Local Outlier Factor scores for each movie represented by its popular features to detect outliers. LOF is a \"normalized distance-based approach where the normalization factor corresponds to the average local data density.\" [Data Mining Textbook]\n",
    "\n",
    "## Local Outlier Factor\n",
    "Intuitively, we find that movies with unusual feature combinations, namely unusual cast ensembles or surprising individual casting choices for the genre, are given the highest LOF score, thus indicating the highest \"outlier\" rating.\n",
    "- The Royal Tenenbaums\n",
    "- Indecent Proposal\n",
    "- Mars Attacks\n",
    "\n",
    "## Isolation Forest\n",
    "Similar to DBSCAN and LOF, we find that feature-rich movies with exceptionally popular \"superstar\" cast are detected as outliers by Isolation Forest. In particular, the biggest outliers have many A-star actors from a wide variety of genres, with some surprising casting choices given the movie genres.\n",
    "- How The West Was Won\n",
    "- Predator 2\n",
    "- Antz\n",
    "- Sleepy Hollow\n",
    "- Batman Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Enable notebook renderer for Altair\n",
    "alt.renderers.enable('default')\n",
    "\n",
    "DATA_PATH = \"../data\"\n",
    "NETFLIX_FOLDER_PATH = os.path.join(DATA_PATH, \"netflix_prize\")\n",
    "IMDB_FOLDER_PATH = os.path.join(DATA_PATH, \"imdb\")\n",
    "MIN_OCCURRENCES = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load movie features\n",
    "MOVIE_FEATURES_PATH = os.path.join(DATA_PATH, f\"processed/movie_features_{MIN_OCCURRENCES}.pickle\")\n",
    "with open(MOVIE_FEATURES_PATH, \"rb\") as f:\n",
    "    movie_features = pickle.load(f)\n",
    "\n",
    "# Load feature mapping\n",
    "FEATURE_MAPPING_PATH = os.path.join(DATA_PATH, f\"processed/feature_mapping_{MIN_OCCURRENCES}.pickle\")\n",
    "with open(FEATURE_MAPPING_PATH, \"rb\") as f:\n",
    "    feature_mapping = pickle.load(f)\n",
    "\n",
    "feature_to_id = feature_mapping['feature_to_id']\n",
    "id_to_feature = feature_mapping['id_to_feature']\n",
    "\n",
    "# Number of features\n",
    "num_features = len(feature_to_id)\n",
    "print(f\"Number of features: {num_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Movie Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of movie IDs and feature IDs\n",
    "movie_ids = list(movie_features.keys())\n",
    "feature_ids = list(id_to_feature.keys())\n",
    "\n",
    "# Create an empty DataFrame\n",
    "movie_feature_matrix = pd.DataFrame(0, index=movie_ids, columns=feature_ids)\n",
    "\n",
    "# Fill the DataFrame\n",
    "for movie_id, features in movie_features.items():\n",
    "    movie_feature_matrix.loc[movie_id, features] = 1\n",
    "\n",
    "print(f\"Movie feature matrix shape: {movie_feature_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Netflix to IMDb mapping\n",
    "NETFLIX_TO_IMDB_PATH = os.path.join(DATA_PATH, \"netflix_to_imdb.json\")\n",
    "with open(NETFLIX_TO_IMDB_PATH, \"r\") as f:\n",
    "    netflix_to_imdb = json.load(f)\n",
    "\n",
    "# Create a mapping from Netflix movie IDs to IMDb IDs\n",
    "netflix_ids = set(movie_ids)\n",
    "netflix_to_imdb_filtered = {nid: imdb_id for nid, imdb_id in netflix_to_imdb.items() if nid in netflix_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IMDb title.basics.tsv.gz\n",
    "TITLE_BASICS_PATH = os.path.join(IMDB_FOLDER_PATH, \"title.basics.tsv.gz\")\n",
    "\n",
    "imdb_titles = {}\n",
    "\n",
    "with gzip.open(TITLE_BASICS_PATH, 'rt', encoding='utf-8') as f:\n",
    "    # Skip header\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) != 9:\n",
    "            continue\n",
    "        tconst, titleType, primaryTitle, originalTitle, isAdult, startYear, endYear, runtimeMinutes, genres = parts\n",
    "        imdb_titles[tconst] = primaryTitle\n",
    "\n",
    "print(f\"Loaded {len(imdb_titles)} IMDb titles.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Netflix movie IDs to titles\n",
    "movie_titles = {}\n",
    "\n",
    "for netflix_id in movie_ids:\n",
    "    imdb_id = netflix_to_imdb_filtered.get(netflix_id)\n",
    "    if imdb_id and imdb_id in imdb_titles:\n",
    "        movie_titles[netflix_id] = imdb_titles[imdb_id]\n",
    "    else:\n",
    "        movie_titles[netflix_id] = f\"Unknown Title ({netflix_id})\"\n",
    "\n",
    "# Add movie titles to the DataFrame\n",
    "movie_feature_matrix['title'] = movie_feature_matrix.index.map(movie_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of feature names for each movie\n",
    "def get_feature_names(feature_ids):\n",
    "    return [id_to_feature[feat_id] for feat_id in feature_ids]\n",
    "\n",
    "movie_feature_matrix['features'] = movie_feature_matrix.index.map(\n",
    "    lambda x: ', '.join(get_feature_names(movie_features.get(x, [])))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Drop the 'title' and 'features' columns to focus on numeric data\n",
    "feature_data = movie_feature_matrix.drop(columns=['title', 'features'])\n",
    "feature_data_scaled = feature_data\n",
    "\n",
    "# Initialize the Local Outlier Factor (LOF) model\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)  # 5% outliers\n",
    "\n",
    "# Fit the model and predict outlier scores\n",
    "lof_scores = -lof.fit_predict(feature_data)\n",
    "# The negative values indicate how strong the outlier effect is (higher means more outlier-like)\n",
    "\n",
    "# Add LOF scores to the original movie feature matrix\n",
    "movie_feature_matrix['LOF_Score'] = lof.negative_outlier_factor_\n",
    "\n",
    "# Sort movies by their LOF score (outliers at the top)\n",
    "outliers = movie_feature_matrix.sort_values(by='LOF_Score', ascending=True)\n",
    "\n",
    "# Display the top potential outliers\n",
    "outliers.head(20)[['title', 'features', 'LOF_Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for plotting\n",
    "plot_data = movie_feature_matrix.copy()\n",
    "\n",
    "# Reset index and ensure column names are strings for Altair compatibility\n",
    "plot_data = plot_data.reset_index(drop=True)\n",
    "plot_data.columns = plot_data.columns.map(str)  # Ensure all column names are strings\n",
    "\n",
    "# Add an 'is_outlier' column to mark outliers\n",
    "plot_data['is_outlier'] = plot_data['LOF_Score'] < -2e+10  # Mark outliers\n",
    "\n",
    "# Identify outliers and inliers\n",
    "outliers = plot_data[plot_data['is_outlier']]\n",
    "inliers = plot_data[~plot_data['is_outlier']]\n",
    "\n",
    "# Calculate the number of inliers to sample to keep total rows <= 5000\n",
    "num_outliers = len(outliers)\n",
    "num_inliers_to_sample = max(5000 - num_outliers, 0)\n",
    "\n",
    "# Sample inliers\n",
    "inliers_sampled = inliers.sample(n=num_inliers_to_sample, random_state=42)\n",
    "\n",
    "# Combine outliers and sampled inliers\n",
    "plot_data_sampled = pd.concat([outliers, inliers_sampled], ignore_index=True)\n",
    "\n",
    "# Prepare feature data for PCA (excluding non-numeric columns)\n",
    "numeric_columns = feature_data.columns.map(str)\n",
    "numeric_data = plot_data_sampled[numeric_columns]\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_results = pca.fit_transform(numeric_data)\n",
    "\n",
    "# Add PCA components to the DataFrame\n",
    "plot_data_sampled['PC1'] = pca_results[:, 0]\n",
    "plot_data_sampled['PC2'] = pca_results[:, 1]\n",
    "\n",
    "# Create a selection object for zooming and panning\n",
    "brush = alt.selection_interval()\n",
    "\n",
    "# Create scatter plot with PCA components, zoom, and tooltips\n",
    "chart = alt.Chart(plot_data_sampled).mark_circle(size=60).encode(\n",
    "    x=alt.X('PC1:Q', scale=alt.Scale(zero=False)),\n",
    "    y=alt.Y('PC2:Q', scale=alt.Scale(zero=False)),\n",
    "    color=alt.condition(\n",
    "        alt.datum.is_outlier,\n",
    "        alt.value('red'),  # Outliers in red\n",
    "        alt.value('rgba(0,0,255,0.1)')  # Inliers in semi-transparent blue\n",
    "    ),\n",
    "    tooltip=[alt.Tooltip('title:N'), alt.Tooltip('LOF_Score:Q'), alt.Tooltip('features:N')]\n",
    ").add_selection(\n",
    "    brush\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    title=\"LOF Outliers (Sampled Data)\"\n",
    ").interactive()\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolation Forest\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Prepare the data by dropping non-numeric columns\n",
    "feature_data = movie_feature_matrix.drop(columns=['title', 'features', 'LOF_Score'], errors='ignore')\n",
    "\n",
    "# Initialize the Isolation Forest model\n",
    "iso_forest = IsolationForest(\n",
    "    n_estimators=100,       # Number of base estimators\n",
    "    contamination=0.05,     # Assume 5% of the data are outliers\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "iso_forest.fit(feature_data)\n",
    "\n",
    "# Get anomaly scores (the lower, the more abnormal)\n",
    "anomaly_scores = iso_forest.decision_function(feature_data)\n",
    "\n",
    "# Predict outliers (-1 for anomalies, 1 for normal instances)\n",
    "outlier_preds = iso_forest.predict(feature_data)\n",
    "\n",
    "# Add scores to the DataFrame\n",
    "movie_feature_matrix['Isolation_Score'] = anomaly_scores\n",
    "movie_feature_matrix['Isolation_Outlier'] = outlier_preds\n",
    "\n",
    "# Sort movies by their anomaly scores (outliers at the top)\n",
    "iso_outliers = movie_feature_matrix.sort_values(by='Isolation_Score')\n",
    "\n",
    "# Display the top potential outliers\n",
    "iso_outliers.head(20)[['title', 'features', 'Isolation_Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for plotting\n",
    "plot_data_iso = movie_feature_matrix.copy()\n",
    "\n",
    "# Reset index and ensure column names are strings for Altair compatibility\n",
    "plot_data_iso = plot_data_iso.reset_index(drop=True)\n",
    "plot_data_iso.columns = plot_data_iso.columns.map(str)\n",
    "\n",
    "# Add an 'is_outlier' column to mark outliers\n",
    "plot_data_iso['is_outlier'] = plot_data_iso['Isolation_Outlier'] == -1  # Mark outliers\n",
    "\n",
    "# Identify outliers and inliers\n",
    "outliers_iso = plot_data_iso[plot_data_iso['is_outlier']]\n",
    "inliers_iso = plot_data_iso[~plot_data_iso['is_outlier']]\n",
    "\n",
    "# Calculate the number of inliers to sample to keep total rows <= 5000\n",
    "num_outliers_iso = len(outliers_iso)\n",
    "num_inliers_to_sample_iso = max(5000 - num_outliers_iso, 0)\n",
    "\n",
    "# Sample inliers\n",
    "inliers_sampled_iso = inliers_iso.sample(n=num_inliers_to_sample_iso, random_state=42)\n",
    "\n",
    "# Combine outliers and sampled inliers\n",
    "plot_data_sampled_iso = pd.concat([outliers_iso, inliers_sampled_iso], ignore_index=True)\n",
    "\n",
    "# Prepare feature data for PCA (excluding non-numeric columns)\n",
    "numeric_columns = feature_data.columns.map(str)\n",
    "numeric_data_iso = plot_data_sampled_iso[numeric_columns]\n",
    "\n",
    "# Apply PCA\n",
    "pca_iso = PCA(n_components=2)\n",
    "pca_results_iso = pca_iso.fit_transform(numeric_data_iso)\n",
    "\n",
    "# Add PCA components to the DataFrame\n",
    "plot_data_sampled_iso['PC1'] = pca_results_iso[:, 0]\n",
    "plot_data_sampled_iso['PC2'] = pca_results_iso[:, 1]\n",
    "\n",
    "# Create a selection object for zooming and panning\n",
    "brush_iso = alt.selection_interval()\n",
    "\n",
    "# Create scatter plot with PCA components, zoom, and tooltips\n",
    "chart_iso = alt.Chart(plot_data_sampled_iso).mark_circle(size=60).encode(\n",
    "    x=alt.X('PC1:Q', scale=alt.Scale(zero=False)),\n",
    "    y=alt.Y('PC2:Q', scale=alt.Scale(zero=False)),\n",
    "    color=alt.condition(\n",
    "        alt.datum.is_outlier,\n",
    "        alt.value('red'),  # Outliers in red\n",
    "        alt.value('rgba(0,0,255,0.1)')  # Inliers in semi-transparent blue\n",
    "    ),\n",
    "    tooltip=[alt.Tooltip('title:N'), alt.Tooltip('Isolation_Score:Q'), alt.Tooltip('features:N')]\n",
    ").add_selection(\n",
    "    brush_iso\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    title=\"Isolation Forest Outliers (Sampled Data)\"\n",
    ").interactive()\n",
    "\n",
    "chart_iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
