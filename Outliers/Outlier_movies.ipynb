{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Detection (Local Outlier Factor - Movies)\n",
    "In this notebook, we compute Local Outlier Factor scores for each movie represented by its popular features to detect outliers. LOF is a \"normalized distance-based approach where the normalization factor corresponds to the average local data density.\" [Data Mining Textbook]\n",
    "\n",
    "Intuitively, we find that movies with unusual feature combinations, namely unusual cast ensembles or surprising individual casting choices for the genre, are given the highest LOF score, thus indicating the highest \"outlier\" rating.\n",
    "- The Royal Tenenbaums\n",
    "- Indecent Proposal\n",
    "- Mars Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Enable notebook renderer for Altair\n",
    "alt.renderers.enable('default')\n",
    "\n",
    "DATA_PATH = \"../data\"\n",
    "NETFLIX_FOLDER_PATH = os.path.join(DATA_PATH, \"netflix_prize\")\n",
    "IMDB_FOLDER_PATH = os.path.join(DATA_PATH, \"imdb\")\n",
    "MIN_OCCURRENCES = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load movie features\n",
    "MOVIE_FEATURES_PATH = os.path.join(DATA_PATH, f\"processed/movie_features_{MIN_OCCURRENCES}.pickle\")\n",
    "with open(MOVIE_FEATURES_PATH, \"rb\") as f:\n",
    "    movie_features = pickle.load(f)\n",
    "\n",
    "# Load feature mapping\n",
    "FEATURE_MAPPING_PATH = os.path.join(DATA_PATH, f\"processed/feature_mapping_{MIN_OCCURRENCES}.pickle\")\n",
    "with open(FEATURE_MAPPING_PATH, \"rb\") as f:\n",
    "    feature_mapping = pickle.load(f)\n",
    "\n",
    "feature_to_id = feature_mapping['feature_to_id']\n",
    "id_to_feature = feature_mapping['id_to_feature']\n",
    "\n",
    "# Number of features\n",
    "num_features = len(feature_to_id)\n",
    "print(f\"Number of features: {num_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Movie Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of movie IDs and feature IDs\n",
    "movie_ids = list(movie_features.keys())\n",
    "feature_ids = list(id_to_feature.keys())\n",
    "\n",
    "# Create an empty DataFrame\n",
    "movie_feature_matrix = pd.DataFrame(0, index=movie_ids, columns=feature_ids)\n",
    "\n",
    "# Fill the DataFrame\n",
    "for movie_id, features in movie_features.items():\n",
    "    movie_feature_matrix.loc[movie_id, features] = 1\n",
    "\n",
    "print(f\"Movie feature matrix shape: {movie_feature_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Netflix to IMDb mapping\n",
    "NETFLIX_TO_IMDB_PATH = os.path.join(DATA_PATH, \"netflix_to_imdb.json\")\n",
    "with open(NETFLIX_TO_IMDB_PATH, \"r\") as f:\n",
    "    netflix_to_imdb = json.load(f)\n",
    "\n",
    "# Create a mapping from Netflix movie IDs to IMDb IDs\n",
    "netflix_ids = set(movie_ids)\n",
    "netflix_to_imdb_filtered = {nid: imdb_id for nid, imdb_id in netflix_to_imdb.items() if nid in netflix_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IMDb title.basics.tsv.gz\n",
    "TITLE_BASICS_PATH = os.path.join(IMDB_FOLDER_PATH, \"title.basics.tsv.gz\")\n",
    "\n",
    "imdb_titles = {}\n",
    "\n",
    "with gzip.open(TITLE_BASICS_PATH, 'rt', encoding='utf-8') as f:\n",
    "    # Skip header\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) != 9:\n",
    "            continue\n",
    "        tconst, titleType, primaryTitle, originalTitle, isAdult, startYear, endYear, runtimeMinutes, genres = parts\n",
    "        imdb_titles[tconst] = primaryTitle\n",
    "\n",
    "print(f\"Loaded {len(imdb_titles)} IMDb titles.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Netflix movie IDs to titles\n",
    "movie_titles = {}\n",
    "\n",
    "for netflix_id in movie_ids:\n",
    "    imdb_id = netflix_to_imdb_filtered.get(netflix_id)\n",
    "    if imdb_id and imdb_id in imdb_titles:\n",
    "        movie_titles[netflix_id] = imdb_titles[imdb_id]\n",
    "    else:\n",
    "        movie_titles[netflix_id] = f\"Unknown Title ({netflix_id})\"\n",
    "\n",
    "# Add movie titles to the DataFrame\n",
    "movie_feature_matrix['title'] = movie_feature_matrix.index.map(movie_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of feature names for each movie\n",
    "def get_feature_names(feature_ids):\n",
    "    return [id_to_feature[feat_id] for feat_id in feature_ids]\n",
    "\n",
    "movie_feature_matrix['features'] = movie_feature_matrix.index.map(\n",
    "    lambda x: ', '.join(get_feature_names(movie_features.get(x, [])))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Drop the 'title' and 'features' columns to focus on numeric data\n",
    "feature_data = movie_feature_matrix.drop(columns=['title', 'features'])\n",
    "feature_data_scaled = feature_data\n",
    "\n",
    "# Initialize the Local Outlier Factor (LOF) model\n",
    "# Setting n_neighbors to a reasonable value (e.g., 20 or 5% of the dataset)\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)  # 5% outliers\n",
    "\n",
    "# Fit the model and predict outlier scores\n",
    "lof_scores = -lof.fit_predict(feature_data)\n",
    "# The negative values indicate how strong the outlier effect is (higher means more outlier-like)\n",
    "\n",
    "# Add LOF scores to the original movie feature matrix\n",
    "movie_feature_matrix['LOF_Score'] = lof.negative_outlier_factor_\n",
    "\n",
    "# Sort movies by their LOF score (outliers at the top)\n",
    "outliers = movie_feature_matrix.sort_values(by='LOF_Score', ascending=True)\n",
    "\n",
    "# Display the top potential outliers\n",
    "print(outliers.head(10)[['title', 'features', 'LOF_Score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers.head(10)[['title', 'features', 'LOF_Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Prepare data for plotting\n",
    "plot_data = movie_feature_matrix.copy()\n",
    "\n",
    "# Reset index and ensure column names are strings for Altair compatibility\n",
    "plot_data = plot_data.reset_index()\n",
    "plot_data.columns = plot_data.columns.map(str)  # Ensure all column names are strings\n",
    "\n",
    "# Add an 'is_outlier' column to mark outliers\n",
    "plot_data['is_outlier'] = plot_data['LOF_Score'] < -2e+10  # Mark outliers\n",
    "\n",
    "\n",
    "# Prepare feature data for PCA (excluding non-numeric columns)\n",
    "numeric_data = movie_feature_matrix.drop(columns=['title', 'features', 'LOF_Score'])\n",
    "numeric_data.columns = numeric_data.columns.map(str)  # Ensure column names are strings\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)  # Reduce to 2 components\n",
    "pca_results = pca.fit_transform(numeric_data)\n",
    "\n",
    "# Add PCA components to the DataFrame\n",
    "plot_data['PC1'] = pca_results[:, 0]\n",
    "plot_data['PC2'] = pca_results[:, 1]\n",
    "\n",
    "# Create a selection object for zooming and panning\n",
    "brush = alt.selection_interval()\n",
    "\n",
    "# Create scatter plot with PCA components, zoom, and tooltips\n",
    "chart = alt.Chart(plot_data).mark_circle(size=60).encode(\n",
    "    x=alt.X('PC1:Q', scale=alt.Scale(zero=False)),\n",
    "    y=alt.Y('PC2:Q', scale=alt.Scale(zero=False)),\n",
    "    color=alt.condition(\n",
    "        alt.datum.is_outlier,\n",
    "        alt.value('red'),  # Mark outliers in red\n",
    "        alt.value('blue')  # Regular points in blue\n",
    "    ),\n",
    "    tooltip=['title:N', 'LOF_Score:Q', 'features:N']  # Add tooltips for hover\n",
    ").add_selection(\n",
    "    brush  # Add zoom and selection functionality\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    title=\"Movie Outliers Highlighted on PCA Components with Zoom and Select\"\n",
    ").interactive()  # Enable zooming and panning\n",
    "\n",
    "chart.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
